{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Multiple views of a storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function full:\n",
      "\n",
      "full(...)\n",
      "    full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Creates a tensor of size :attr:`size` filled with :attr:`fill_value`. The\n",
      "    tensor's dtype is inferred from :attr:`fill_value`.\n",
      "    \n",
      "    Args:\n",
      "        size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "            shape of the output tensor.\n",
      "        fill_value (Scalar): the value to fill the output tensor with.\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.full((2, 3), 3.141592)\n",
      "        tensor([[ 3.1416,  3.1416,  3.1416],\n",
      "                [ 3.1416,  3.1416,  3.1416]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = torch.full((13,13), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[1,:] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[:,1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[6,:] = 2\n",
    "M1[:,6] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[-2,:] = 2\n",
    "M1[:, -2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[3:5,3:5] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[-5:-3,-5:-3] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[-5:-3,3:5] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1[3:5,-5:-3] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Eigendecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = torch.empty((20,20)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5132, -0.1468, -0.6762, -0.8069,  0.8709, -0.4873, -0.1080, -0.2883,\n",
       "          1.5503, -1.4598, -0.6214, -0.2545, -0.4611,  0.4778, -0.2775,  1.6090,\n",
       "         -1.0120,  0.8780,  0.7154, -1.6513],\n",
       "        [ 0.4724,  0.5487, -1.1771,  0.7316,  0.4109, -1.6936, -0.9428,  0.0847,\n",
       "         -0.5176, -0.7307,  0.6935,  1.0609,  1.0536, -1.1629, -0.7287,  0.3495,\n",
       "          0.0205,  0.1041,  0.2318,  0.4573],\n",
       "        [-0.3097,  1.6856,  1.2120, -1.2476,  0.6440,  0.1132,  0.9974, -1.0773,\n",
       "          1.3555, -1.3442,  1.7749, -0.4374,  0.5214, -0.3502,  0.3599, -0.9537,\n",
       "         -1.0971, -0.0551,  2.2685, -0.6753],\n",
       "        [ 0.2616, -0.4989,  0.8576,  0.2134, -0.1510,  1.0030,  0.3836, -0.6416,\n",
       "         -1.0000,  0.9143, -1.1682,  1.8007,  1.5956,  0.0319, -0.4120, -0.8811,\n",
       "          1.9753, -1.3399,  0.2613, -0.8519],\n",
       "        [ 0.7059, -1.1844,  1.2464,  1.1347,  0.5431,  0.2933,  1.7257, -0.7292,\n",
       "         -0.9309, -0.2476, -0.9095, -0.4233,  1.4408,  0.2298, -0.3781,  0.7842,\n",
       "         -0.5774,  0.1310,  1.0716,  0.8399],\n",
       "        [-0.6591, -0.3335, -0.8753, -1.7145, -0.4901, -0.8781,  0.1692, -0.6446,\n",
       "         -0.6285,  0.1100,  0.5228, -0.2217,  0.0964,  2.2212, -1.1692, -1.2084,\n",
       "         -0.5049, -0.1285,  0.6390, -2.4404],\n",
       "        [-0.6125, -1.3424,  1.5493, -0.3484,  0.5967, -0.8268,  0.9818, -0.3656,\n",
       "          0.2210, -0.3852, -0.5849, -0.5267, -2.0656, -0.3093, -1.4109,  0.5089,\n",
       "          0.2377,  0.9058, -0.2099, -0.2847],\n",
       "        [ 1.2166,  0.5844,  0.9979,  0.7817, -1.9755,  1.2533,  0.7541,  0.6214,\n",
       "         -1.2948, -0.6551,  1.8998,  0.1178,  0.8433, -0.6702,  0.1969,  0.9038,\n",
       "          1.4418, -0.1917, -2.7424,  0.4579],\n",
       "        [ 1.7965, -0.6614,  1.1664, -0.4175,  0.1478,  1.0090,  0.2669,  0.1427,\n",
       "          0.8136,  1.0513, -0.8215, -0.0148, -0.8855,  0.5260, -1.0068, -0.2182,\n",
       "         -1.6189, -0.0283,  1.0303, -0.3583],\n",
       "        [ 1.6767,  0.2165, -1.3032,  2.4478,  1.3950, -0.6005, -0.7471, -0.0554,\n",
       "          0.4307, -0.6534, -1.6495, -1.5868, -0.9566, -0.8794, -0.3650,  0.1501,\n",
       "         -1.3122,  0.7646, -0.5645, -1.5253],\n",
       "        [ 0.2518,  0.2862,  0.0614,  1.8278,  0.4960,  0.8303, -0.3115,  0.7553,\n",
       "         -0.6972, -0.7016,  0.8781, -0.0497, -0.2894,  1.6957,  1.1459, -0.5255,\n",
       "          0.5079,  0.0951,  0.6118, -0.6139],\n",
       "        [-1.1362, -0.4407,  0.6185,  0.4261,  1.5500, -0.7516,  0.5210, -0.4591,\n",
       "         -0.0687, -0.3663,  0.0181,  0.0294, -0.9300, -0.4592, -0.3409,  0.5432,\n",
       "          1.0262, -0.5850, -0.3462, -0.8374],\n",
       "        [-0.3968, -0.9696, -1.3223,  1.3447,  2.9096, -1.0675, -0.4794, -1.4749,\n",
       "         -1.5007, -1.5472, -1.4387, -1.3432,  0.2487, -1.9066,  0.7988,  0.5725,\n",
       "         -0.2085, -0.7231,  0.8328, -1.2385],\n",
       "        [-0.0683,  0.4368,  0.6956, -0.7298,  1.0845,  0.7929, -1.0417,  1.6321,\n",
       "         -0.6800,  0.5136,  1.2566,  0.4628, -0.1534,  1.8473,  0.0680, -0.9686,\n",
       "          1.6857,  1.1416, -1.7900,  2.0700],\n",
       "        [-0.4001,  0.7138, -2.6970, -1.9806, -1.3004,  1.9445, -1.3450, -1.0546,\n",
       "         -0.3310,  1.5715, -0.4942,  1.6109,  0.1576,  0.1781, -0.0977,  0.1312,\n",
       "         -0.1298,  0.2112,  0.0995,  0.0252],\n",
       "        [ 0.2839,  0.2745, -1.0062, -0.9750,  1.1348, -1.3855, -0.3953,  1.5129,\n",
       "          0.5238, -0.9371, -0.3270,  0.3606, -0.5356, -0.1995,  1.3335,  0.6997,\n",
       "         -0.5543,  1.5026, -0.2976, -1.2302],\n",
       "        [-1.7459,  1.1649,  1.7084,  0.1877,  0.1386,  1.5276, -0.7586, -0.8354,\n",
       "         -0.8028, -1.4804, -0.7590, -0.3410,  2.0997, -0.3815, -0.0400, -0.2600,\n",
       "         -0.6657,  1.8724,  0.5788, -0.4191],\n",
       "        [-0.8533, -0.1892, -1.0388,  0.4267, -0.6730,  1.6227,  0.1401, -0.5494,\n",
       "         -0.8855, -0.3546,  3.1830,  1.0141,  0.6651, -0.8418,  0.8183, -0.6622,\n",
       "          0.5741, -0.8459, -0.8933, -1.4751],\n",
       "        [ 1.2709, -1.4346,  1.3198, -1.0170, -1.8577,  1.4305, -0.0505, -0.6343,\n",
       "          0.5933, -0.7486,  1.3726, -1.3326, -1.8083, -1.2969, -0.8432, -0.6823,\n",
       "          1.0305,  1.2177,  0.0790, -2.0937],\n",
       "        [ 1.2554, -0.2346,  1.4243,  1.2176, -1.2252, -0.2074, -1.5190, -1.5499,\n",
       "         -0.6115, -0.7769, -1.9237, -0.8734,  2.0990,  0.4956,  1.0982, -0.3198,\n",
       "         -0.7440,  0.7313,  0.1110,  0.6792]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need the inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function inverse:\n",
      "\n",
      "inverse(...)\n",
      "    inverse(input, *, out=None) -> Tensor\n",
      "    \n",
      "    Takes the inverse of the square matrix :attr:`input`. :attr:`input` can be batches\n",
      "    of 2D square tensors, in which case this function would return a tensor composed of\n",
      "    individual inverses.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "        Irrespective of the original strides, the returned tensors will be\n",
      "        transposed, i.e. with strides like `input.contiguous().transpose(-2, -1).stride()`\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor of size :math:`(*, n, n)` where `*` is zero or more\n",
      "                        batch dimensions\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.rand(4, 4)\n",
      "        >>> y = torch.inverse(x)\n",
      "        >>> z = torch.mm(x, y)\n",
      "        >>> z\n",
      "        tensor([[ 1.0000, -0.0000, -0.0000,  0.0000],\n",
      "                [ 0.0000,  1.0000,  0.0000,  0.0000],\n",
      "                [ 0.0000,  0.0000,  1.0000,  0.0000],\n",
      "                [ 0.0000, -0.0000, -0.0000,  1.0000]])\n",
      "        >>> torch.max(torch.abs(z - torch.eye(4))) # Max non-zero\n",
      "        tensor(1.1921e-07)\n",
      "        >>> # Batched inverse example\n",
      "        >>> x = torch.randn(2, 3, 4, 4)\n",
      "        >>> y = torch.inverse(x)\n",
      "        >>> z = torch.matmul(x, y)\n",
      "        >>> torch.max(torch.abs(z - torch.eye(4).expand_as(x))) # Max non-zero\n",
      "        tensor(1.9073e-06)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here then it makes a copy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2_inv = torch.inverse(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8170e-03,  7.0653e-02,  1.2589e-01,  6.5774e-02,  6.9209e-02,\n",
       "          4.8582e-03, -1.5382e-02,  1.2220e-01,  9.6284e-02,  7.2854e-02,\n",
       "          1.6613e-02, -1.8632e-02,  4.1683e-02,  7.7191e-02,  7.8622e-02,\n",
       "          7.0768e-02, -1.5915e-01, -6.7357e-02,  4.9481e-02,  7.4368e-02],\n",
       "        [-1.8778e-01,  8.3826e-03,  1.6041e-01, -6.8975e-02, -6.2702e-02,\n",
       "          5.1849e-02, -1.0736e-01,  1.5569e-01, -4.0893e-02,  9.6935e-02,\n",
       "          9.4697e-02,  3.1794e-01, -8.8464e-02, -9.5372e-02,  1.6602e-01,\n",
       "          2.5320e-02,  1.0876e-01, -2.4211e-01, -5.5307e-02, -6.1800e-02],\n",
       "        [-1.2764e-01,  2.0478e-02, -3.9458e-02, -9.6855e-02, -4.8761e-02,\n",
       "          4.9710e-03, -1.2497e-01,  2.6190e-02,  2.2757e-01, -1.3505e-01,\n",
       "         -1.5195e-03,  4.3160e-01, -7.2311e-02, -5.4323e-02, -5.8926e-02,\n",
       "          6.8740e-02,  1.2928e-01, -4.1007e-02,  2.6391e-02,  1.0329e-01],\n",
       "        [-6.0964e-02,  6.2630e-02, -7.8493e-02, -4.3812e-02,  9.9739e-02,\n",
       "         -6.4288e-02, -4.1306e-02, -1.1845e-01, -8.3342e-02,  1.4060e-01,\n",
       "          1.3105e-01,  1.8812e-01, -1.9020e-01, -8.8069e-02, -2.1288e-02,\n",
       "         -5.9782e-02,  3.8535e-02,  7.8469e-02,  1.5717e-03,  2.0121e-02],\n",
       "        [ 1.1221e-02, -4.9086e-03,  6.6771e-02, -7.6037e-03,  1.2223e-01,\n",
       "         -1.2218e-02, -1.3910e-01, -4.9573e-02,  9.9797e-02,  7.7997e-02,\n",
       "         -9.1681e-02,  2.5653e-01,  4.9466e-02,  1.9097e-01,  2.2246e-02,\n",
       "          5.0144e-02, -1.1384e-02,  4.0482e-02, -7.8805e-03, -1.6519e-02],\n",
       "        [ 1.8670e-01, -1.1971e-01,  2.6791e-02,  1.2244e-01, -6.3704e-02,\n",
       "         -1.0982e-01,  1.0053e-01,  8.1225e-02,  8.3958e-02,  2.4435e-02,\n",
       "          5.1883e-02, -3.6417e-01,  1.4314e-01,  8.9366e-02,  2.5229e-02,\n",
       "         -1.3576e-01,  2.7388e-02,  5.7644e-02, -2.3025e-02, -1.0366e-01],\n",
       "        [-4.3135e-02, -1.7790e-01,  1.7107e-01,  1.5290e-01,  1.9384e-01,\n",
       "          1.1256e-03,  3.0674e-01,  4.6836e-02, -2.5520e-01,  1.5615e-01,\n",
       "         -2.1686e-02, -3.3142e-01, -5.5468e-02, -3.9904e-02,  2.0537e-02,\n",
       "          7.6054e-02, -9.3613e-02,  5.5600e-02, -1.1892e-01, -1.2019e-01],\n",
       "        [ 4.6082e-02,  8.4821e-03, -1.9620e-01,  5.4981e-02, -1.5308e-01,\n",
       "         -9.8836e-03, -1.1762e-01,  2.2007e-02,  1.0196e-01, -1.2943e-01,\n",
       "          4.0626e-02, -3.6415e-01,  9.6433e-02, -4.9645e-02, -2.6690e-01,\n",
       "          3.2428e-02,  1.4129e-01, -9.6524e-02,  1.3693e-02, -2.6366e-01],\n",
       "        [ 2.8627e-01, -5.6771e-02,  7.4515e-02,  1.2882e-01,  3.3676e-02,\n",
       "         -1.4830e-01, -1.3017e-01, -1.6183e-01, -1.2886e-01,  1.6125e-01,\n",
       "         -1.6676e-01, -3.3909e-02, -1.8682e-01,  1.0475e-01, -1.0915e-01,\n",
       "         -8.3728e-02, -1.4666e-01,  1.0108e-01,  6.0746e-02,  6.0313e-02],\n",
       "        [-5.1387e-01, -1.7254e-02, -2.4831e-01, -4.3793e-01,  4.7347e-01,\n",
       "          1.0997e-01, -8.9238e-01, -3.0185e-01,  5.5691e-02,  3.2233e-02,\n",
       "         -1.7762e-01,  1.3854e+00, -4.4872e-01, -1.1935e-01,  1.6788e-01,\n",
       "          2.3151e-01,  1.9290e-01, -9.3625e-02,  2.8359e-01,  2.8324e-03],\n",
       "        [-1.0886e-01,  1.3311e-01, -3.0595e-02, -2.7076e-01,  2.0000e-01,\n",
       "          5.4479e-02, -3.4224e-01, -7.5815e-02,  7.2283e-02, -5.1632e-02,\n",
       "         -2.4665e-02,  5.2738e-01, -1.4756e-01,  3.3645e-02,  2.4898e-02,\n",
       "          3.1567e-02,  1.3906e-02,  8.9640e-02,  1.4762e-01,  2.4782e-02],\n",
       "        [ 9.7395e-02,  1.3766e-01,  1.0595e-01,  2.6157e-01, -1.6291e-01,\n",
       "         -1.1998e-01,  5.5108e-01,  3.4764e-02,  9.1396e-02, -1.8321e-02,\n",
       "          1.2685e-01, -3.6577e-01, -1.1350e-02, -1.5015e-02,  7.0099e-02,\n",
       "          8.4696e-02, -9.1797e-02,  2.1822e-01, -2.3487e-01,  9.5405e-02],\n",
       "        [ 6.4863e-02,  2.6157e-02, -8.2826e-02,  5.8374e-03,  2.5001e-01,\n",
       "          6.0471e-02, -4.7672e-01, -9.2979e-02, -5.8458e-02,  3.5636e-02,\n",
       "         -2.4078e-01,  2.1546e-01, -1.1414e-01,  7.8472e-02, -1.1705e-01,\n",
       "          3.2469e-02,  7.2752e-02,  2.1883e-02,  1.1548e-01, -2.5417e-03],\n",
       "        [ 1.5155e-01, -4.2073e-02,  3.5777e-02,  1.1843e-02,  3.8319e-02,\n",
       "          1.0750e-01,  4.2123e-02,  5.0666e-02, -6.7054e-03,  1.6225e-02,\n",
       "          1.3583e-01,  1.8275e-03, -4.0501e-02,  9.2693e-02,  4.1630e-02,\n",
       "         -6.3543e-02, -1.1026e-01, -2.7131e-02, -7.4698e-02,  9.7252e-02],\n",
       "        [-1.6090e-01, -1.8299e-01,  2.8388e-02, -8.6382e-02,  6.0681e-02,\n",
       "         -7.7432e-02, -9.1927e-02, -7.1574e-02, -6.5103e-02, -7.3398e-02,\n",
       "          5.5391e-02,  2.2288e-01, -3.7955e-02, -7.2707e-02,  6.4793e-02,\n",
       "          2.4683e-01, -5.5125e-02,  7.0481e-02,  3.4864e-04,  1.5120e-01],\n",
       "        [ 1.2641e-02,  1.0464e-01, -1.6315e-01, -3.1697e-01,  2.5822e-01,\n",
       "          1.7143e-02, -5.4101e-01,  1.0287e-01,  1.6181e-01, -1.5207e-01,\n",
       "          3.2958e-02,  8.5104e-01, -1.1860e-01, -1.0645e-01,  1.6634e-01,\n",
       "          8.5363e-02,  6.7099e-02, -2.0849e-01,  1.6223e-01,  1.4802e-02],\n",
       "        [ 2.4565e-03,  1.5720e-02,  8.1101e-03,  9.2159e-02,  1.4937e-01,\n",
       "         -2.7956e-02, -2.5599e-01, -5.0019e-02, -2.7335e-01,  3.0323e-02,\n",
       "          4.3337e-02,  2.9099e-01, -8.5502e-02,  6.2053e-02,  6.5671e-02,\n",
       "         -6.1926e-03, -5.7199e-02, -2.0817e-01,  2.3241e-01, -4.7533e-02],\n",
       "        [-2.1267e-01,  4.6203e-02, -2.7684e-02, -1.4589e-01,  3.9366e-01,\n",
       "          3.9033e-03, -1.0631e-01, -2.0601e-01, -2.1494e-01,  1.5798e-01,\n",
       "         -2.0583e-02,  3.9666e-01, -3.0999e-01,  3.0466e-02,  1.7278e-01,\n",
       "          2.4732e-01,  1.1221e-01,  2.4974e-02,  1.7882e-01,  3.2824e-02],\n",
       "        [-1.0564e-01,  1.3677e-01, -3.6506e-02, -9.4760e-02,  1.2826e-01,\n",
       "         -1.5217e-02, -2.3487e-01, -1.3438e-01,  3.5991e-03, -1.5832e-01,\n",
       "          2.0081e-01,  1.8298e-01, -2.0217e-02, -1.3745e-01,  5.0111e-02,\n",
       "          7.7975e-03,  7.6422e-02, -1.9603e-01,  1.7790e-01, -1.0762e-01],\n",
       "        [ 9.6003e-02,  1.6481e-02,  9.4149e-02,  4.9204e-02, -7.0378e-02,\n",
       "         -1.3398e-01,  3.3519e-01,  1.8192e-02, -8.4005e-02, -4.1596e-02,\n",
       "          1.2647e-02, -5.0648e-01,  1.3121e-01,  1.1417e-01, -4.5268e-03,\n",
       "         -1.6545e-01, -1.1728e-01,  1.6534e-02, -1.2312e-01,  8.9053e-03]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now want a diagonal matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function diag:\n",
      "\n",
      "diag(...)\n",
      "    diag(input, diagonal=0, *, out=None) -> Tensor\n",
      "    \n",
      "    - If :attr:`input` is a vector (1-D tensor), then returns a 2-D square tensor\n",
      "      with the elements of :attr:`input` as the diagonal.\n",
      "    - If :attr:`input` is a matrix (2-D tensor), then returns a 1-D tensor with\n",
      "      the diagonal elements of :attr:`input`.\n",
      "    \n",
      "    The argument :attr:`diagonal` controls which diagonal to consider:\n",
      "    \n",
      "    - If :attr:`diagonal` = 0, it is the main diagonal.\n",
      "    - If :attr:`diagonal` > 0, it is above the main diagonal.\n",
      "    - If :attr:`diagonal` < 0, it is below the main diagonal.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        diagonal (int, optional): the diagonal to consider\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    .. seealso::\n",
      "    \n",
      "            :func:`torch.diagonal` always returns the diagonal of its input.\n",
      "    \n",
      "            :func:`torch.diagflat` always constructs a tensor with diagonal elements\n",
      "            specified by the input.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    Get the square matrix where the input vector is the diagonal::\n",
      "    \n",
      "        >>> a = torch.randn(3)\n",
      "        >>> a\n",
      "        tensor([ 0.5950,-0.0872, 2.3298])\n",
      "        >>> torch.diag(a)\n",
      "        tensor([[ 0.5950, 0.0000, 0.0000],\n",
      "                [ 0.0000,-0.0872, 0.0000],\n",
      "                [ 0.0000, 0.0000, 2.3298]])\n",
      "        >>> torch.diag(a, 1)\n",
      "        tensor([[ 0.0000, 0.5950, 0.0000, 0.0000],\n",
      "                [ 0.0000, 0.0000,-0.0872, 0.0000],\n",
      "                [ 0.0000, 0.0000, 0.0000, 2.3298],\n",
      "                [ 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "    \n",
      "    Get the k-th diagonal of a given matrix::\n",
      "    \n",
      "        >>> a = torch.randn(3, 3)\n",
      "        >>> a\n",
      "        tensor([[-0.4264, 0.0255,-0.1064],\n",
      "                [ 0.8795,-0.2429, 0.1374],\n",
      "                [ 0.1029,-0.6482,-1.6300]])\n",
      "        >>> torch.diag(a, 0)\n",
      "        tensor([-0.4264,-0.2429,-1.6300])\n",
      "        >>> torch.diag(a, 1)\n",
      "        tensor([ 0.0255, 0.1374])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = torch.diag(torch.arange(20) + 1).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 11.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 12.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 13.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 14.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         15.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0., 16.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0., 17.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0., 18.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0., 19.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0., 20.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now want to compute the product M2_inv * diag * M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function mm:\n",
      "\n",
      "mm(...)\n",
      "    mm(input, mat2, *, out=None) -> Tensor\n",
      "    \n",
      "    Performs a matrix multiplication of the matrices :attr:`input` and :attr:`mat2`.\n",
      "    \n",
      "    If :attr:`input` is a :math:`(n \\times m)` tensor, :attr:`mat2` is a\n",
      "    :math:`(m \\times p)` tensor, :attr:`out` will be a :math:`(n \\times p)` tensor.\n",
      "    \n",
      "    .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "              For broadcasting matrix products, see :func:`torch.matmul`.\n",
      "    \n",
      "    This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the first matrix to be multiplied\n",
      "        mat2 (Tensor): the second matrix to be multiplied\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> mat1 = torch.randn(2, 3)\n",
      "        >>> mat2 = torch.randn(3, 3)\n",
      "        >>> torch.mm(mat1, mat2)\n",
      "        tensor([[ 0.4851,  0.5037, -0.3633],\n",
      "                [-0.0760, -3.6705,  2.4784]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need both to be same type, so convert types to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = torch.mm(M2_inv, torch.mm(diag, M2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now want to get eigenvalues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function eig:\n",
      "\n",
      "eig(...)\n",
      "    eig(input, eigenvectors=False, *, out=None) -> (Tensor, Tensor)\n",
      "    \n",
      "    Computes the eigenvalues and eigenvectors of a real square matrix.\n",
      "    \n",
      "    .. note::\n",
      "        Since eigenvalues and eigenvectors might be complex, backward pass is supported only\n",
      "        for :func:`torch.symeig`\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the square matrix of shape :math:`(n \\times n)` for which the eigenvalues and eigenvectors\n",
      "            will be computed\n",
      "        eigenvectors (bool): ``True`` to compute both eigenvalues and eigenvectors;\n",
      "            otherwise, only eigenvalues will be computed\n",
      "    \n",
      "    Keyword args:\n",
      "        out (tuple, optional): the output tensors\n",
      "    \n",
      "    Returns:\n",
      "        (Tensor, Tensor): A namedtuple (eigenvalues, eigenvectors) containing\n",
      "    \n",
      "            - **eigenvalues** (*Tensor*): Shape :math:`(n \\times 2)`. Each row is an eigenvalue of ``input``,\n",
      "              where the first element is the real part and the second element is the imaginary part.\n",
      "              The eigenvalues are not necessarily ordered.\n",
      "            - **eigenvectors** (*Tensor*): If ``eigenvectors=False``, it's an empty tensor.\n",
      "              Otherwise, this tensor of shape :math:`(n \\times n)` can be used to compute normalized (unit length)\n",
      "              eigenvectors of corresponding eigenvalues as follows.\n",
      "              If the corresponding `eigenvalues[j]` is a real number, column `eigenvectors[:, j]` is the eigenvector\n",
      "              corresponding to `eigenvalues[j]`.\n",
      "              If the corresponding `eigenvalues[j]` and `eigenvalues[j + 1]` form a complex conjugate pair, then the\n",
      "              true eigenvectors can be computed as\n",
      "              :math:`\\text{true eigenvector}[j] = eigenvectors[:, j] + i \\times eigenvectors[:, j + 1]`,\n",
      "              :math:`\\text{true eigenvector}[j + 1] = eigenvectors[:, j] - i \\times eigenvectors[:, j + 1]`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two columns for real and imaginary\n",
    "eigvals, _ = torch.eig(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000],\n",
       "        [20.0000,  0.0000],\n",
       "        [19.0000,  0.0000],\n",
       "        [ 2.0000,  0.0000],\n",
       "        [ 3.0000,  0.0000],\n",
       "        [ 4.0000,  0.0000],\n",
       "        [ 5.0000,  0.0000],\n",
       "        [ 6.0000,  0.0000],\n",
       "        [18.0000,  0.0000],\n",
       "        [ 7.0000,  0.0000],\n",
       "        [ 8.0000,  0.0000],\n",
       "        [ 9.0000,  0.0000],\n",
       "        [10.0000,  0.0000],\n",
       "        [17.0000,  0.0000],\n",
       "        [11.0000,  0.0000],\n",
       "        [12.0000,  0.0000],\n",
       "        [16.0000,  0.0000],\n",
       "        [15.0000,  0.0000],\n",
       "        [13.0000,  0.0000],\n",
       "        [14.0000,  0.0000]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Flops per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_1 = torch.empty((5000,5000)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_2 = torch.empty((5000,5000)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 4.442264521999732 s\n"
     ]
    }
   ],
   "source": [
    "# prod w timing \n",
    "t_start = time.perf_counter()\n",
    "prod_3 = torch.mm(M3_1, M3_2)\n",
    "t_end = time.perf_counter()\n",
    "time_elapsed = t_end - t_start\n",
    "print(\"time elapsed:\", time_elapsed, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 5000])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many floating point products have been executed per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each element in the NxN matrix, there are (2N-1) operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_operations(N):\n",
    "    return (2*N-1)*N**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_op = get_n_operations(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per second \n",
    "n_op_per_second = n_op / time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56271975422.001915"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_op_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.271975422001915"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_op_per_second / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "56 billion ops per second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Playing with strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "M4 = torch.full((1000, 400), 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_row(M):\n",
    "    M_new = torch.empty((M.shape[0], M.shape[1]))\n",
    "    \n",
    "    # no slicing operators allowed? \n",
    "    for i in range(len(M)):\n",
    "        slice_M = M[i]\n",
    "        mult_M = slice_M * (i+1)\n",
    "        M_new[i] = mult_M\n",
    "    return M_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication in  0.03638779099946987  s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "mul_row(M4)\n",
    "end_time = time.perf_counter()\n",
    "slow_time = end_time - start_time \n",
    "print(\"multiplication in \", slow_time, \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now write mul_row_fast using tensor operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_row_fast(M):\n",
    "    return torch.mul(torch.arange(1, M.shape[0]+1).view(M.shape[0], 1), M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication in  0.0014155260005281889  s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "mul_row_fast(M4)\n",
    "end_time = time.perf_counter()\n",
    "fast_time = end_time - start_time \n",
    "print(\"multiplication in \", fast_time, \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.42699956706213"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_mul_time / fast_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
